1.BIO与NIO
    1.1 BIO
        1.1.1 BIO服务端的两次阻塞:
            a.首先需要等待客户端的连接请求(第一次阻塞), 如果没有客户端连接, 服务端将一直阻塞等待
            b.然后当客户端连接后, 服务器会等待客户端发送数据(第二次阻塞), 如果客户端没有发送数据, 那么服务端将会一直阻塞等待客户端发送数据
    1.2 NIO
        1.2.1 Buffer缓冲区:
            状态变量: 
                position: 跟踪[已经写了]多少数据。更准确地说, 它指定了[下一个字节]将放到数组的哪一个位置中, position从0开始
                limit: 表明还有多少数据需要取出(在从缓冲区写入通道时), 或者还有多少空间可以放入数据(在从通道读入缓冲区时)
                       position 总是小于或者等于 limit
                capacity: 缓冲区的 capacity 表明可以储存在缓冲区中的最大数据容量。它指定了底层数组的大小 ― 或者至少是指定了准许
                          我们使用的底层数组的容量。limit 决不能大于 capacity
                0 <= position <= limit <= capacity
    1.3 IO模型
        1.3.1 概念
            文件描述符: Linux 的内核将所有外部设备都看做一个文件来操作, 对一个文件的读写操作会调用内核提供的系统命令(api), 
                返回一个file descriptor(fd, 文件描述符)。而对一个socket的读写也会有响应的描述符, 称为socket fd(socket文件描述
                符), 描述符就是一个数字, 指向内核中的一个结构体(文件路径, 数据区等一些属性)
                   
    参见: http://www.52im.net/forum.php?mod=viewthread&tid=2846
    
2.Netty
    2.1 简介
        Netty 是一个高性能、异步事件驱动的 NIO 框架, 它提供了对 TCP、UDP 和文件传输的支持, 作为一个异步 NIO 框架, Netty 的所有
        IO 操作都是[异步非阻塞]的, 通过 Future-Listener 机制, 用户可以方便的主动获取或者通过通知机制获得 IO 操作结果
    2.2 高性能特点
        2.2.1 传统RPC性能低的原因
            原因一: 网络传输方式
                传统的 RPC 框架或者基于 RMI 等方式的远程服务(过程)调用采用了同步阻塞 IO(BIO), 当客户端的并发压力或者网络时延增
                大之后, 同步阻塞 IO 会由于频繁的 wait 导致 IO 线程经常性的阻塞, 由于线程无法高效的工作, IO 处理能力自然下降
            原因二: 序列化方式
            原因三: 线程模型
                由于采用同步阻塞 IO, 这会导致每个 TCP 连接都占用1个线程, 由于线程资源是 JVM 虚拟机非常宝贵的资源, 当 IO 读写阻
                塞导致线程无法及时释放时, 会导致系统性能急剧下降, 严重的甚至会导致虚拟机无法创建新的线程
        2.2.2 Netty高性能的原因
            原因一: 异步非阻塞通信
                在 IO 编程过程中, 当需要同时处理多个客户端接入请求时, 可以利用多线程或者 [IO多路复用技术]进行处理。IO多路复用技
                术通过把多个 IO 的阻塞复用到同一个 select 的阻塞上, 从而使得系统在单线程的情况下可以同时处理多个客户端请求。与
                传统的多线程 / 多进程模型比, I/O 多路复用的最大优势是系统开销小, 系统不需要创建新的额外进程或者线程, 也不需要维
                护这些进程和线程的运行, 降低了系统的维护工作量, 节省了系统资源
            原因二: 零拷贝
                a.Netty 的接收和发送 ByteBuffer 采用 [DIRECT BUFFERS], 使用[堆外直接内存]进行 Socket 读写, 不需要进行字节缓冲
                区的二次拷贝。如果使用传统的堆内存(HEAP BUFFERS)进行 Socket 读写, JVM 会将堆内存 Buffer 拷贝一份到直接内存中,
                然后才写入 Socket 中。相比于堆外直接内存, 消息在发送过程中多了一次缓冲区的内存拷贝
                b.Netty 提供了组合 Buffer 对象, 可以聚合多个 ByteBuffer 对象, 用户可以像操作一个 Buffer 那样方便的对组合 
                Buffer 进行操作, 避免了传统通过内存拷贝的方式将几个小 Buffer 合并成一个大的 Buffer
                c.Netty 的文件传输采用了 transferTo 方法, 它可以直接将文件缓冲区的数据发送到目标 Channel, 避免了传统通过循环 
                write 方式导致的内存拷贝问题
            原因三: 内存池
            原因四: Reactor线程模型
                1.三种线程模型
                    a.Reactor单线程模型
                        Reactor反应器和Handlers处理器处于一个线程中执行
                    b.Reactor多线程模型
                        引入多个selector选择器
                        设计一个新的子反应 [subReactor]类, 一个子反应器负责查询一个selector选择器, 一个选择器上可能对应多个
                        Channel通道
                        开启多个反应器的处理线程, 一个线程负责执行一个子反应器
                    c.主从Reactor多线程模型
                2.Netty中的Reactor反应器模式
                    step1: Channel通道注册。IO源于通道, 一次IO事件一定属于某个通道。通道注册到selector选择器后, IO事件会
                        被选择器查询到。
                    step2: Reactor查询选择。一个反应器(或子反应器)会负责一个线程, 不断地轮询, 查询选择器中的IO事件。
                    step3: Reactor事件分发。如果反应器在选择器上查询到IO事件, 则分发给IO事件绑定的Handler处理器上。
                    step4: Handler事件处理。
    2.3 ByteBuf
        2.3.1 ByteBuf缓冲区类型
            Heap ByteBuf
                内部数据为一个java数组, 存储在JVM堆空间
                未池化的情况下, 能提供快速的分配和释放
                写入底层传输通道之前, 都会复制到直接缓冲区(不足, 效率低)
            Direct ByteBuf
                内部数据存储在操作系统的物理内存中
                能获取超过JVM堆空间的内存空间; 写入传输通道比堆缓冲区快
                释放和分配空间昂贵; 在java中操作时都需要复制一次到堆上
            CompositeBuffer
                多个缓冲区的组合表示
                方便一次操作多个缓冲区实例 
                